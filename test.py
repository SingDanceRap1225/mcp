import asyncio
from llm_model.ai_app import AIApp
from typing import Optional
from contextlib import AsyncExitStack
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from utills import format_available_tools, handle_tool_call


class MCPClient:
    def __init__(self):
        self.app: AIApp = None
        self.session = None
        self.exit_stack = AsyncExitStack()
        self.session: Optional[ClientSession] = None

    def get_server_params(self, server_script_path: str):
        """æ ¹æ®serveræ–‡ä»¶ç±»å‹å¯åŠ¨server"""

        if server_script_path.endswith('.py'):
            command = "python"
            args = [server_script_path]
        elif server_script_path.endswith('.jar'):
            command = "java"
            args = ["-Dfile.encoding=UTF-8",
                    "-jar", server_script_path,
                    "-Dspring.ai.mcp.server.stdio=true",
                    "-Dspring.main.web-application-type=none",
                    "-Dlogging.pattern.console="]
        else:
            raise ValueError("ä¸æ”¯æŒçš„è„šæœ¬æ–‡ä»¶ç±»å‹ï¼Œä»…æ”¯æŒ .py æˆ– .jar æ–‡ä»¶")

        return StdioServerParameters(command=command, args=args, env=None)

    async def connect_to_mcp_server(self, server_script_path: str):
        """ä½¿ç”¨LLMæŸ¥è¯¢å¹¶è°ƒç”¨MCPServer"""

        # å¯åŠ¨MCP server
        server_params = self.get_server_params(server_script_path)
        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))
        self.stdio, self.write = stdio_transport
        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))
        await self.session.initialize()

        # åˆ—å‡ºMCPServerä¸Šçš„å·¥å…·
        mcp_response = await self.session.list_tools()
        tools = mcp_response.tools
        print("å·²è¿æ¥MCPæœåŠ¡å™¨ï¼Œæ”¯æŒä»¥ä¸‹å·¥å…·ï¼š\n", [tool.name for tool in tools])
        available_tools = format_available_tools(mcp_response)

        # åˆå§‹åŒ–LLMï¼Œå¹¶å°†å¯ç”¨çš„MCPServerå·¥å…·æ³¨å…¥
        self.app = AIApp(config_file='llm_model/config.ini', tools=available_tools)

    async def process_query(self, query: str) -> str:
        """æŠŠè¾“å…¥æé—®æäº¤LLM"""
        response = self.app.generate_response(1, query)

        content = response.choices[0]
        print(content)
        # LLMéœ€è¦è°ƒç”¨MCP server
        if content.finish_reason == "tool_calls":
            tool_name, tool_args = handle_tool_call(content)

            # æ‰§è¡ŒMCPServerå·¥å…·
            print(f"Calling tool {tool_name} with args {tool_args}")
            result = await self.session.call_tool(tool_name, tool_args)
            # å°†æ¨¡å‹è°ƒç”¨çš„serverå·¥å…·è¿”å›ç»“æœè¿åŒåˆå§‹æé—®å†å–‚ç»™å¤§æ¨¡å‹
            response = self.app.generate_response(2, query + "\n" + result.content[0].text)

        response_text = response.choices[0].message.content

        return response_text

    async def chat_loop(self):
        """è¿è¡Œäº¤äº’å¼èŠå¤©å¾ªç¯"""

        print("\nMCP å®¢æˆ·ç«¯å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")
        while True:
            try:
                query = input("\nQuery: ").strip()
                if query.lower() == 'quit':
                    break
                response = await self.process_query(query) # å‘é€ç”¨æˆ·è¾“å…¥åˆ°LLM
                print(f"\nğŸ¤– AI: {response}")
            except Exception as e:
                print(f"\nâš ï¸ å‘ç”Ÿé”™è¯¯: {str(e)}")

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        await self.exit_stack.aclose()


async def main():
    client = MCPClient()
    try:
        # å¯åŠ¨å¹¶è¿æ¥MCP Server
        # await client.connect_to_mcp_server("mcp_server/mcp-server-0.0.1-SNAPSHOT.jar")
        await client.connect_to_mcp_server("mcp_server/mcp_server_starter.py")
        await client.chat_loop()
    finally:
        await client.cleanup()


if __name__ == "__main__":
    asyncio.run(main())
